{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0aa6e42",
   "metadata": {},
   "source": [
    "### üìÇ Carregamento do Dataset Refinado\n",
    "Este trecho localiza automaticamente a raiz do projeto, constr√≥i o caminho at√© df_base.parquet e carrega o dataset j√° tratado utilizando pandas.\n",
    "\n",
    "Tamb√©m valida se o arquivo existe e exibe o shape e os tipos das colunas, garantindo que a base est√° correta antes de iniciar a etapa de modelagem, conforme as boas pr√°ticas do projeto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66eea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset: (3030, 13)\n",
      "\n",
      "Tipos de dados:\n",
      "\n",
      "RA               str\n",
      "ANO            int64\n",
      "IDADE        float64\n",
      "FASE           Int64\n",
      "IAA          float64\n",
      "IEG          float64\n",
      "IDA          float64\n",
      "IAN          float64\n",
      "IPS          float64\n",
      "IPV          float64\n",
      "NOTA_MAT     float64\n",
      "NOTA_POR     float64\n",
      "DEFASAGEM    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Descobre a raiz do projeto (assume que o notebook est√° em notbooks/)\n",
    "try:\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    # __file__ n√£o existe em notebooks; usa o cwd como base\n",
    "    ROOT = Path.cwd().resolve().parent\n",
    "\n",
    "data_path = ROOT / 'data' / 'refined' / 'df_base.parquet'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Arquivo n√£o encontrado: {data_path}\")\n",
    "\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(\"Shape do dataset:\", df.shape)\n",
    "print(\"\\nTipos de dados:\\n\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3001e",
   "metadata": {},
   "source": [
    "### üéØ Constru√ß√£o da Vari√°vel Target (ABANDONO)\n",
    "\n",
    "Este trecho prepara a base para modelagem e define corretamente o target ABANDONO.\n",
    "\n",
    "Primeiro, filtramos apenas fases v√°lidas (1 a 8) e ordenamos os dados por aluno (RA) e ano, permitindo an√°lise temporal. Em seguida, criamos uma flag que indica se o aluno apareceu no ano seguinte.\n",
    "\n",
    "Como 2024 n√£o possui ano posterior, marcamos apenas anos anteriores como observ√°veis para abandono.\n",
    "\n",
    "Por fim, definimos ABANDONO = 1 quando:\n",
    "\n",
    " - O aluno estava em fase ativa (< 8),\n",
    "\n",
    " - O ano √© observ√°vel (< 2024),\n",
    "\n",
    " - E o aluno n√£o apareceu no ano seguinte.\n",
    "\n",
    "Ao final, realizamos verifica√ß√µes b√°sicas (sanity checks) para validar a distribui√ß√£o do target antes do treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a411dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape ap√≥s filtro de fases: (2375, 13)\n",
      "\n",
      "Distribui√ß√£o do target ABANDONO (apenas anos observ√°veis):\n",
      "ABANDONO\n",
      "0    0.721\n",
      "1    0.279\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Abandono por FASE (anos observ√°veis):\n",
      "FASE\n",
      "1    23.3\n",
      "2    25.4\n",
      "3    36.1\n",
      "4    31.2\n",
      "5    33.6\n",
      "6    43.1\n",
      "7    29.5\n",
      "8     0.0\n",
      "Name: ABANDONO, dtype: float64\n",
      "RA                           str\n",
      "ANO                        int64\n",
      "IDADE                    float64\n",
      "FASE                       Int64\n",
      "IAA                      float64\n",
      "IEG                      float64\n",
      "IDA                      float64\n",
      "IAN                      float64\n",
      "IPS                      float64\n",
      "IPV                      float64\n",
      "NOTA_MAT                 float64\n",
      "NOTA_POR                 float64\n",
      "DEFASAGEM                float64\n",
      "PRESENTE_ANO_SEGUINTE       bool\n",
      "OBSERVAVEL_ABANDONO        int64\n",
      "ABANDONO                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# 0) Par√¢metros do dataset\n",
    "# ----------------------------------\n",
    "ANO_MAX = 2024\n",
    "\n",
    "# ----------------------------------\n",
    "# 1) Filtra apenas fases v√°lidas (1 a 8)\n",
    "# ----------------------------------\n",
    "df = df[df[\"FASE\"].between(1, 8)].copy()\n",
    "print(\"Shape ap√≥s filtro de fases:\", df.shape)\n",
    "\n",
    "# ----------------------------------\n",
    "# 2) Ordena para an√°lise temporal\n",
    "# ----------------------------------\n",
    "df = df.sort_values([\"RA\", \"ANO\"])\n",
    "\n",
    "# ----------------------------------\n",
    "# 3) Cria flag de presen√ßa no ano seguinte\n",
    "#    (apenas observacional)\n",
    "# ----------------------------------\n",
    "df[\"PRESENTE_ANO_SEGUINTE\"] = (\n",
    "    df.groupby(\"RA\")[\"ANO\"]\n",
    "      .shift(-1)\n",
    "      .eq(df[\"ANO\"] + 1)\n",
    ")\n",
    "\n",
    "df[\"PRESENTE_ANO_SEGUINTE\"] = (\n",
    "    df[\"PRESENTE_ANO_SEGUINTE\"]\n",
    "    .fillna(False)\n",
    ")\n",
    "\n",
    "# ----------------------------------\n",
    "# 4) Marca se o abandono √© observ√°vel\n",
    "#    (2024 n√£o √© observ√°vel)\n",
    "# ----------------------------------\n",
    "df[\"OBSERVAVEL_ABANDONO\"] = (df[\"ANO\"] < ANO_MAX).astype(int)\n",
    "\n",
    "# ----------------------------------\n",
    "# 5) Define ABANDONO corretamente\n",
    "#    - fase ativa (< 8)\n",
    "#    - ano observ√°vel (< 2024)\n",
    "#    - n√£o apareceu no ano seguinte\n",
    "# ----------------------------------\n",
    "df[\"ABANDONO\"] = (\n",
    "    (df[\"FASE\"] < 8) &\n",
    "    (df[\"OBSERVAVEL_ABANDONO\"] == 1) &\n",
    "    (~df[\"PRESENTE_ANO_SEGUINTE\"])\n",
    ").astype(int)\n",
    "\n",
    "# ----------------------------------\n",
    "# 6) Sanity checks\n",
    "# ----------------------------------\n",
    "print(\"\\nDistribui√ß√£o do target ABANDONO (apenas anos observ√°veis):\")\n",
    "print(\n",
    "    df.loc[df[\"OBSERVAVEL_ABANDONO\"] == 1, \"ABANDONO\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .round(3)\n",
    ")\n",
    "\n",
    "print(\"\\nAbandono por FASE (anos observ√°veis):\")\n",
    "print(\n",
    "    df.loc[df[\"OBSERVAVEL_ABANDONO\"] == 1]\n",
    "      .groupby(\"FASE\")[\"ABANDONO\"]\n",
    "      .mean()\n",
    "      .round(3) * 100\n",
    ")\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f13d02",
   "metadata": {},
   "source": [
    "### üß± Dataset Final de Treinamento\n",
    "\n",
    "Este bloco monta o df_train apenas com registros onde o abandono √© observ√°vel (at√© 2023) e com fases trein√°veis (1 a 7). Em seguida, remove colunas que n√£o devem entrar no treino (ID e vari√°veis t√©cnicas/poss√≠vel vazamento), padroniza os tipos de dados (incluindo o target ABANDONO) e reorganiza as colunas no formato ‚Äúcontrato‚Äù esperado pelo modelo.\n",
    "\n",
    "Por fim, executa sanity checks para garantir que:\n",
    "\n",
    " - n√£o existe 2024 no treino,\n",
    "\n",
    " - n√£o existe FASE 8,\n",
    "\n",
    " - ABANDONO est√° apenas em {0,1},\n",
    "   e imprime o schema e distribui√ß√µes para valida√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b08c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape ap√≥s filtros (OBSERVAVEL + FASE 1‚Äì7): (1390, 16)\n",
      "\n",
      "Schema final (processed/train):\n",
      "ANO            int64\n",
      "IDADE          Int64\n",
      "FASE           Int64\n",
      "DEFASAGEM      Int64\n",
      "IAA          float64\n",
      "IEG          float64\n",
      "IDA          float64\n",
      "IAN          float64\n",
      "IPS          float64\n",
      "IPV          float64\n",
      "NOTA_MAT     float64\n",
      "NOTA_POR     float64\n",
      "ABANDONO       int64\n",
      "dtype: object\n",
      "\n",
      "Shape: (1390, 13)\n",
      "\n",
      "Distribui√ß√£o do target:\n",
      "ABANDONO\n",
      "0    0.708\n",
      "1    0.292\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Abandono por FASE:\n",
      "FASE\n",
      "1    23.3\n",
      "2    25.4\n",
      "3    36.1\n",
      "4    31.2\n",
      "5    33.6\n",
      "6    43.1\n",
      "7    29.5\n",
      "Name: ABANDONO, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ANO_MAX = 2024\n",
    "\n",
    "# ----------------------------------\n",
    "# 1) Dataset FINAL para TREINAMENTO\n",
    "#    - somente anos observ√°veis (<=2023)\n",
    "#    - somente fases trein√°veis (1 a 7)\n",
    "# ----------------------------------\n",
    "df_train = df[\n",
    "    (df[\"OBSERVAVEL_ABANDONO\"] == 1) &\n",
    "    (df[\"FASE\"].between(1, 7))\n",
    "].copy()\n",
    "\n",
    "print(\"Shape ap√≥s filtros (OBSERVAVEL + FASE 1‚Äì7):\", df_train.shape)\n",
    "\n",
    "# ----------------------------------\n",
    "# 2) Remove colunas que n√£o podem ir para treino (vazamento / t√©cnico / id)\n",
    "# ----------------------------------\n",
    "cols_to_drop = [\"RA\", \"PRESENTE_ANO_SEGUINTE\", \"OBSERVAVEL_ABANDONO\"]\n",
    "df_train = df_train.drop(columns=[c for c in cols_to_drop if c in df_train.columns])\n",
    "\n",
    "# ----------------------------------\n",
    "# 3) Garante dtypes (contrato)\n",
    "# ----------------------------------\n",
    "df_train[\"ANO\"] = df_train[\"ANO\"].astype(\"int64\")\n",
    "\n",
    "# FASE e FASE_IDEAL como inteiros nulos (se tiver NaN, mant√©m)\n",
    "df_train[\"FASE\"] = df_train[\"FASE\"].astype(\"Int64\")\n",
    "#df_train[\"FASE_IDEAL\"] = df_train[\"FASE_IDEAL\"].astype(\"Int64\")\n",
    "\n",
    "# idade/defasagem: se forem conceitualmente inteiras, padroniza\n",
    "df_train[\"IDADE\"] = df_train[\"IDADE\"].round().astype(\"Int64\")\n",
    "df_train[\"DEFASAGEM\"] = df_train[\"DEFASAGEM\"].round().astype(\"Int64\")\n",
    "\n",
    "# target\n",
    "df_train[\"ABANDONO\"] = df_train[\"ABANDONO\"].astype(\"int64\")\n",
    "\n",
    "# ----------------------------------\n",
    "# 4) Ordena colunas (contrato)\n",
    "# ----------------------------------\n",
    "\n",
    "cols_order = [\n",
    "    \"ANO\", \"IDADE\", \"FASE\", \"DEFASAGEM\",\n",
    "    \"IAA\", \"IEG\", \"IDA\", \"IAN\", \"IPS\", \"IPV\",\n",
    "    \"NOTA_MAT\", \"NOTA_POR\",\n",
    "    \"ABANDONO\"\n",
    "]\n",
    "\n",
    "# garante que todas existem (se alguma n√£o existir, falha cedo)\n",
    "missing_cols = [c for c in cols_order if c not in df_train.columns]\n",
    "assert not missing_cols, f\"Colunas faltando no df_train: {missing_cols}\"\n",
    "\n",
    "df_train = df_train[cols_order]\n",
    "\n",
    "# ----------------------------------\n",
    "# 5) Sanity checks\n",
    "# ----------------------------------\n",
    "assert df_train[\"ABANDONO\"].isin([0, 1]).all(), \"ABANDONO cont√©m valores fora de {0,1}\"\n",
    "assert df_train[\"ANO\"].max() <= (ANO_MAX - 1), \"Treino cont√©m 2024 (n√£o observ√°vel)\"\n",
    "assert df_train[\"FASE\"].max() <= 7, \"Treino cont√©m FASE 8 (n√£o trein√°vel para abandono)\"\n",
    "assert df_train[\"FASE\"].min() >= 1, \"Treino cont√©m FASE < 1\"\n",
    "\n",
    "print(\"\\nSchema final (processed/train):\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nShape:\", df_train.shape)\n",
    "\n",
    "print(\"\\nDistribui√ß√£o do target:\")\n",
    "print(df_train[\"ABANDONO\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "print(\"\\nAbandono por FASE:\")\n",
    "print((df_train.groupby(\"FASE\")[\"ABANDONO\"].mean() * 100).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42064c9c",
   "metadata": {},
   "source": [
    "### üîé An√°lise de Valores Nulos\n",
    "\n",
    "Este trecho calcula a quantidade e o percentual de valores nulos em cada coluna do df_train.\n",
    "\n",
    "Em seguida, organiza essas informa√ß√µes em um DataFrame resumido (null_summary), ordenado do maior para o menor percentual de nulos.\n",
    "\n",
    "Essa etapa √© importante para identificar poss√≠veis problemas de qualidade dos dados antes do treinamento do modelo, orientando decis√µes como imputa√ß√£o ou exclus√£o de vari√°veis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4e747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nulos  % nulos\n",
      "NOTA_POR      16     1.15\n",
      "NOTA_MAT      16     1.15\n",
      "IDA           14     1.01\n",
      "IEG           13     0.94\n",
      "IPV           13     0.94\n",
      "IPS            6     0.43\n",
      "IAA            0     0.00\n",
      "FASE           0     0.00\n",
      "IDADE          0     0.00\n",
      "ANO            0     0.00\n",
      "DEFASAGEM      0     0.00\n",
      "IAN            0     0.00\n",
      "ABANDONO       0     0.00\n"
     ]
    }
   ],
   "source": [
    "# quantidade de nulos por coluna\n",
    "null_count = df_train.isna().sum()\n",
    "\n",
    "# percentual de nulos por coluna\n",
    "null_pct = (df_train.isna().mean() * 100).round(2)\n",
    "\n",
    "null_summary = (\n",
    "    pd.DataFrame({\n",
    "        \"nulos\": null_count,\n",
    "        \"% nulos\": null_pct\n",
    "    })\n",
    "    .sort_values(\"% nulos\", ascending=False)\n",
    ")\n",
    "\n",
    "print(null_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed66a8f",
   "metadata": {},
   "source": [
    "### üìä Nulos por Fase\n",
    "\n",
    "Este trecho calcula o percentual de valores nulos por coluna dentro de cada FASE.\n",
    "\n",
    "Agrupamos o dataset por FASE e medimos a propor√ß√£o de NaN em cada vari√°vel, permitindo identificar se a aus√™ncia de dados est√° concentrada em fases espec√≠ficas.\n",
    "\n",
    "Essa an√°lise ajuda a entender padr√µes estruturais de missing e evita decis√µes equivocadas de imputa√ß√£o global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9cfc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ANO  IDADE  DEFASAGEM  IAA   IEG   IDA  IAN  IPS   IPV  NOTA_MAT  \\\n",
      "FASE                                                                     \n",
      "1     0.0    0.0        0.0  0.0   0.0   0.0  0.0  0.0   0.0       0.0   \n",
      "2     0.0    0.0        0.0  0.0   0.0   0.3  0.0  0.0   0.0       0.3   \n",
      "3     0.0    0.0        0.0  0.0   0.0   0.0  0.0  0.0   0.0       0.7   \n",
      "4     0.0    0.0        0.0  0.0   0.0   0.0  0.0  3.5   0.0       0.0   \n",
      "5     0.0    0.0        0.0  0.0   0.0   0.0  0.0  0.0   0.0       0.0   \n",
      "6     0.0    0.0        0.0  0.0   0.0   0.0  0.0  0.0   0.0       0.0   \n",
      "7     0.0    0.0        0.0  0.0  29.5  29.5  0.0  0.0  29.5      29.5   \n",
      "\n",
      "      NOTA_POR  ABANDONO  \n",
      "FASE                      \n",
      "1          0.0       0.0  \n",
      "2          0.3       0.0  \n",
      "3          0.7       0.0  \n",
      "4          0.0       0.0  \n",
      "5          0.0       0.0  \n",
      "6          0.0       0.0  \n",
      "7         29.5       0.0  \n"
     ]
    }
   ],
   "source": [
    "nulls_por_fase = (\n",
    "    df_train\n",
    "    .groupby(\"FASE\")\n",
    "    .apply(lambda x: x.isna().mean())\n",
    "    .round(3) * 100\n",
    ")\n",
    "\n",
    "print(nulls_por_fase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4098d",
   "metadata": {},
   "source": [
    "### ü©π Imputa√ß√£o de Nulos por Fase\n",
    "\n",
    "Esta fun√ß√£o trata valores faltantes em vari√°veis num√©ricas imputando a mediana dentro de cada FASE, para respeitar diferen√ßas naturais entre n√≠veis de aprendizado.\n",
    "\n",
    "Fluxo aplicado:\n",
    "\n",
    "(Opcional) cria flags *_MISSING indicando quais valores eram nulos antes da imputa√ß√£o.\n",
    "\n",
    "Imputa cada coluna pela mediana da pr√≥pria FASE.\n",
    "\n",
    "Se a FASE n√£o tiver mediana v√°lida (ex.: grupo todo nulo), usa a mediana global da coluna como fallback.\n",
    "\n",
    "Se ainda restarem nulos (caso extremo), preenche com 0 para evitar falhas no treino.\n",
    "\n",
    "Ao final, o c√≥digo gera df_train_imp e valida que as colunas imputadas n√£o ficaram com NaN, inclusive por FASE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046f482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDA</th>\n",
       "      <th>IEG</th>\n",
       "      <th>IPV</th>\n",
       "      <th>IPS</th>\n",
       "      <th>NOTA_MAT</th>\n",
       "      <th>NOTA_POR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FASE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IDA  IEG  IPV  IPS  NOTA_MAT  NOTA_POR\n",
       "FASE                                        \n",
       "1     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "2     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "3     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "4     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "5     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "6     0.0  0.0  0.0  0.0       0.0       0.0\n",
       "7     0.0  0.0  0.0  0.0       0.0       0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imputar_nulos_por_fase(\n",
    "    df_train,\n",
    "    fase_col=\"FASE\",\n",
    "    cols_imputar=(\"IDA\", \"IEG\", \"IPV\", \"IPS\", \"NOTA_MAT\", \"NOTA_POR\"),\n",
    "    add_missing_flags=True,\n",
    "    suffix_missing=\"_MISSING\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Imputa nulos de colunas num√©ricas usando a mediana por FASE.\n",
    "    Tamb√©m pode criar flags de missing (0/1) para cada coluna imputada.\n",
    "\n",
    "    Regras:\n",
    "      1) Se add_missing_flags=True: cria COL_MISSING = 1 se era nulo, sen√£o 0\n",
    "      2) Imputa√ß√£o principal: mediana por grupo (FASE)\n",
    "      3) Fallback: se a mediana do grupo for NaN (ex.: grupo todo nulo),\n",
    "         usa a mediana global da coluna.\n",
    "\n",
    "    Retorna:\n",
    "      df (c√≥pia) com imputa√ß√µes e flags (se habilitado)\n",
    "    \"\"\"\n",
    "    df = df_train.copy()\n",
    "\n",
    "    # valida√ß√µes m√≠nimas\n",
    "    if fase_col not in df.columns:\n",
    "        raise ValueError(f\"Coluna '{fase_col}' n√£o existe no dataframe.\")\n",
    "\n",
    "    # garante que cols_imputar existem\n",
    "    cols_existentes = [c for c in cols_imputar if c in df.columns]\n",
    "    cols_faltantes = [c for c in cols_imputar if c not in df.columns]\n",
    "    if cols_faltantes:\n",
    "        # n√£o quebra; apenas ignora as faltantes (√∫til em diferentes vers√µes do dataset)\n",
    "        pass\n",
    "\n",
    "    # cria flags de missing antes de imputar\n",
    "    if add_missing_flags:\n",
    "        for col in cols_existentes:\n",
    "            df[f\"{col}{suffix_missing}\"] = df[col].isna().astype(int)\n",
    "\n",
    "    # imputa√ß√£o por mediana da fase, com fallback global\n",
    "    for col in cols_existentes:\n",
    "        # mediana global (fallback)\n",
    "        global_med = df[col].median()\n",
    "\n",
    "        # mediana por fase\n",
    "        med_por_fase = df.groupby(fase_col)[col].median()\n",
    "\n",
    "        # fun√ß√£o que resolve mediana do grupo com fallback global\n",
    "        def _fill_group(s):\n",
    "            med = med_por_fase.get(s.name)\n",
    "            if med != med:  # NaN check sem numpy\n",
    "                med = global_med\n",
    "            return s.fillna(med)\n",
    "\n",
    "        df[col] = df.groupby(fase_col, group_keys=False)[col].apply(_fill_group)\n",
    "\n",
    "        # fallback final: se ainda sobrar NaN (coluna inteira NaN), zera\n",
    "        if df[col].isna().any():\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_imp = imputar_nulos_por_fase(df_train)\n",
    "\n",
    "# checar nulos nas colunas imputadas\n",
    "cols = [\"IDA\", \"IEG\", \"IPV\", \"IPS\", \"NOTA_MAT\", \"NOTA_POR\"]\n",
    "df_train_imp[cols].isna().sum()\n",
    "\n",
    "df_train_imp.groupby(\"FASE\")[cols].apply(lambda x: x.isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d25e9",
   "metadata": {},
   "source": [
    "### üìã Inspe√ß√£o Final do Dataset\n",
    "\n",
    "O comando df_train_imp.info() exibe um resumo estrutural do dataset ap√≥s a imputa√ß√£o.\n",
    "\n",
    "Essa verifica√ß√£o confirma que n√£o h√° mais valores faltantes nas colunas tratadas e que os tipos est√£o corretos antes de iniciar o treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd63283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "Index: 1390 entries, 0 to 3015\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ANO               1390 non-null   int64  \n",
      " 1   IDADE             1390 non-null   Int64  \n",
      " 2   FASE              1390 non-null   Int64  \n",
      " 3   DEFASAGEM         1390 non-null   Int64  \n",
      " 4   IAA               1390 non-null   float64\n",
      " 5   IEG               1390 non-null   float64\n",
      " 6   IDA               1390 non-null   float64\n",
      " 7   IAN               1390 non-null   float64\n",
      " 8   IPS               1390 non-null   float64\n",
      " 9   IPV               1390 non-null   float64\n",
      " 10  NOTA_MAT          1390 non-null   float64\n",
      " 11  NOTA_POR          1390 non-null   float64\n",
      " 12  ABANDONO          1390 non-null   int64  \n",
      " 13  IDA_MISSING       1390 non-null   int64  \n",
      " 14  IEG_MISSING       1390 non-null   int64  \n",
      " 15  IPV_MISSING       1390 non-null   int64  \n",
      " 16  IPS_MISSING       1390 non-null   int64  \n",
      " 17  NOTA_MAT_MISSING  1390 non-null   int64  \n",
      " 18  NOTA_POR_MISSING  1390 non-null   int64  \n",
      "dtypes: Int64(3), float64(8), int64(8)\n",
      "memory usage: 221.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_train_imp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2500e",
   "metadata": {},
   "source": [
    "### üìä Ajuste de Tipos e Correla√ß√£o com o Target\n",
    "\n",
    "Primeiro, convertemos IDADE, FASE e DEFASAGEM para int64, garantindo consist√™ncia num√©rica no dataset.\n",
    "\n",
    "Em seguida, calculamos a correla√ß√£o das vari√°veis num√©ricas com o target ABANDONO, ordenando do maior para o menor valor.\n",
    "\n",
    "Essa an√°lise ajuda a identificar quais features possuem maior associa√ß√£o linear com o abandono, servindo como uma verifica√ß√£o explorat√≥ria antes da modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a555f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ABANDONO            1.000000\n",
       "IDADE               0.150355\n",
       "FASE                0.091992\n",
       "IPS_MISSING         0.030105\n",
       "IPS                 0.011176\n",
       "NOTA_POR_MISSING   -0.024820\n",
       "NOTA_MAT_MISSING   -0.024820\n",
       "IDA_MISSING        -0.048947\n",
       "IAA                -0.061138\n",
       "IPV_MISSING        -0.062412\n",
       "IEG_MISSING        -0.062412\n",
       "ANO                -0.070615\n",
       "IAN                -0.113902\n",
       "DEFASAGEM          -0.150276\n",
       "NOTA_MAT           -0.200993\n",
       "NOTA_POR           -0.239882\n",
       "IDA                -0.255344\n",
       "IPV                -0.279362\n",
       "IEG                -0.342927\n",
       "Name: ABANDONO, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols = [\"IDADE\", \"FASE\", \"DEFASAGEM\"]\n",
    "df_train_imp[int_cols] = df_train_imp[int_cols].astype(\"int64\")\n",
    "\n",
    "df_train_imp.corr(numeric_only=True)[\"ABANDONO\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475ae68",
   "metadata": {},
   "source": [
    "### üíæ Salvando o Dataset Processado\n",
    "\n",
    "Este trecho salva o dataset final de treinamento (df_train_imp) no formato Parquet, dentro da pasta data/processed.\n",
    "\n",
    "O arquivo √© exportado sem √≠ndice, utilizando o engine pyarrow e compress√£o snappy, garantindo efici√™ncia de armazenamento e leitura.\n",
    "\n",
    "Esse passo consolida a base pronta para ser utilizada na etapa de treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce01d55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Parquet salvo em ../data/processed/df_trein.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = '../data/processed/df_trein.parquet'\n",
    "df_train_imp.to_parquet(output_path, index=False, engine='pyarrow', compression='snappy')\n",
    "print(f'Arquivo Parquet salvo em {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
