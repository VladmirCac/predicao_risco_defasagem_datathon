{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f11e74",
   "metadata": {},
   "source": [
    "### üì• Carregamento da Base Processada\n",
    "\n",
    "Este trecho localiza automaticamente a raiz do projeto e carrega o arquivo df_trein.parquet da pasta data/processed.\n",
    "\n",
    "Ap√≥s validar que o arquivo existe, o dataset √© lido com pandas e s√£o exibidos o shape e os tipos das colunas, garantindo que a base est√° pronta para a etapa de modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d1e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset: (1390, 19)\n",
      "\n",
      "Tipos de dados:\n",
      "\n",
      "ANO                   int64\n",
      "IDADE                 int64\n",
      "FASE                  int64\n",
      "DEFASAGEM             int64\n",
      "IAA                 float64\n",
      "IEG                 float64\n",
      "IDA                 float64\n",
      "IAN                 float64\n",
      "IPS                 float64\n",
      "IPV                 float64\n",
      "NOTA_MAT            float64\n",
      "NOTA_POR            float64\n",
      "ABANDONO              int64\n",
      "IDA_MISSING           int64\n",
      "IEG_MISSING           int64\n",
      "IPV_MISSING           int64\n",
      "IPS_MISSING           int64\n",
      "NOTA_MAT_MISSING      int64\n",
      "NOTA_POR_MISSING      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Descobre a raiz do projeto (assume que o notebook est√° em notbooks/)\n",
    "try:\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    # __file__ n√£o existe em notebooks; usa o cwd como base\n",
    "    ROOT = Path.cwd().resolve().parent\n",
    "\n",
    "data_path = ROOT / 'data' / 'processed' / 'df_trein.parquet'\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Arquivo n√£o encontrado: {data_path}\")\n",
    "\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(\"Shape do dataset:\", df.shape)\n",
    "print(\"\\nTipos de dados:\\n\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7919695",
   "metadata": {},
   "source": [
    "### üìå Baseline com Regress√£o Log√≠stica (2022 ‚Üí 2023)\n",
    "\n",
    "Este bloco treina um modelo baseline de classifica√ß√£o usando Regress√£o Log√≠stica dentro de um Pipeline, avaliando de forma temporal: treino em 2022 e teste (holdout) em 2023.\n",
    "\n",
    "O fluxo √©:\n",
    "\n",
    " - Sanity checks: garante que o target ABANDONO existe e que os anos no dataset s√£o apenas 2022 e 2023.\n",
    "\n",
    " - Separa√ß√£o de features e target e divis√£o temporal (2022/2023).\n",
    "\n",
    "Pipeline com:\n",
    "\n",
    " - RobustScaler: reduz o impacto de outliers nas vari√°veis num√©ricas.\n",
    "\n",
    " - LogisticRegression com class_weight=\"balanced\": trata o desbalanceamento dando mais peso √† classe de abandono.\n",
    "\n",
    " - Avalia√ß√£o por probabilidade com m√©tricas independentes de limiar:\n",
    "\n",
    " - ROC-AUC e PR-AUC no holdout 2023.\n",
    "\n",
    " - Avalia√ß√£o com threshold 0.5 (padr√£o) e, adicionalmente, um threshold ‚Äú√≥timo‚Äù por F1 (apenas diagn√≥stico) para entender o trade-off entre precis√£o e recall, exibindo matriz de confus√£o e relat√≥rio de classifica√ß√£o em ambos os casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a3005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (2023 holdout): 0.6532\n",
      "PR-AUC  (2023 holdout): 0.4191\n",
      "\n",
      "Confusion (thr=0.50):\n",
      "[[500  32]\n",
      " [149  39]]\n",
      "\n",
      "Report (thr=0.50):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.770     0.940     0.847       532\n",
      "           1      0.549     0.207     0.301       188\n",
      "\n",
      "    accuracy                          0.749       720\n",
      "   macro avg      0.660     0.574     0.574       720\n",
      "weighted avg      0.713     0.749     0.704       720\n",
      "\n",
      "\n",
      "Melhor threshold por F1 no holdout: 0.302\n",
      "F1=0.475 | Precision=0.384 | Recall=0.622\n",
      "\n",
      "Confusion (best_thr):\n",
      "[[343 189]\n",
      " [ 71 117]]\n",
      "\n",
      "Report (best_thr):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.829     0.645     0.725       532\n",
      "           1      0.382     0.622     0.474       188\n",
      "\n",
      "    accuracy                          0.639       720\n",
      "   macro avg      0.605     0.634     0.599       720\n",
      "weighted avg      0.712     0.639     0.659       720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vladm/Dev/predicao_risco_defasagem_datathon/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "TARGET = \"ABANDONO\"\n",
    "\n",
    "# ---- sanity checks ----\n",
    "assert TARGET in df.columns, f\"Target {TARGET} n√£o est√° no dataset\"\n",
    "assert set(df[\"ANO\"].unique()) == {2022, 2023}, \"Esperado ANO em {2022, 2023}\"\n",
    "\n",
    "features = [c for c in df.columns if c != TARGET]\n",
    "\n",
    "train = df[df[\"ANO\"] == 2022].copy()\n",
    "test  = df[df[\"ANO\"] == 2023].copy()\n",
    "\n",
    "X_train, y_train = train[features], train[TARGET]\n",
    "X_test,  y_test  = test[features],  test[TARGET]\n",
    "\n",
    "# ---- baseline model ----\n",
    "\"\"\"pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",   # importante para classe desbalanceada\n",
    "        solver=\"lbfgs\"\n",
    "    ))\n",
    "])\"\"\"\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", RobustScaler()),\n",
    "    (\"lr\", LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"liblinear\",   # bom para L1/L2 em datasets menores\n",
    "        penalty=\"l2\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©tricas ‚Äúagn√≥sticas a limiar‚Äù\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "ap  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(f\"ROC-AUC (2023 holdout): {roc:.4f}\")\n",
    "print(f\"PR-AUC  (2023 holdout): {ap:.4f}\")\n",
    "\n",
    "# ---- avalia√ß√£o com limiar padr√£o 0.5 ----\n",
    "pred_05 = (proba >= 0.5).astype(int)\n",
    "print(\"\\nConfusion (thr=0.50):\")\n",
    "print(confusion_matrix(y_test, pred_05))\n",
    "print(\"\\nReport (thr=0.50):\")\n",
    "print(classification_report(y_test, pred_05, digits=3))\n",
    "\n",
    "# ---- achar limiar que maximiza F1 no holdout (apenas para diagn√≥stico) ----\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "\n",
    "best_idx = f1.argmax()\n",
    "best_thr = thr[best_idx - 1] if best_idx > 0 else 0.5\n",
    "\n",
    "print(f\"\\nMelhor threshold por F1 no holdout: {best_thr:.3f}\")\n",
    "print(f\"F1={f1[best_idx]:.3f} | Precision={prec[best_idx]:.3f} | Recall={rec[best_idx]:.3f}\")\n",
    "\n",
    "pred_best = (proba >= best_thr).astype(int)\n",
    "print(\"\\nConfusion (best_thr):\")\n",
    "print(confusion_matrix(y_test, pred_best))\n",
    "print(\"\\nReport (best_thr):\")\n",
    "print(classification_report(y_test, pred_best, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22909f4d",
   "metadata": {},
   "source": [
    "### üìä Import√¢ncia das Vari√°veis (Regress√£o Log√≠stica)\n",
    "\n",
    "Este trecho extrai os coeficientes do modelo de Regress√£o Log√≠stica treinado e organiza em um DataFrame para an√°lise.\n",
    "\n",
    "Os coeficientes representam o impacto de cada vari√°vel no risco de abandono:\n",
    "\n",
    " - Coeficiente positivo ‚Üí aumenta a probabilidade de abandono.\n",
    "\n",
    " - Coeficiente negativo ‚Üí reduz a probabilidade de abandono.\n",
    "\n",
    "As vari√°veis s√£o ordenadas pelo valor absoluto do coeficiente (abs_coef), destacando as features com maior influ√™ncia no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7639d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IEG</td>\n",
       "      <td>-0.929160</td>\n",
       "      <td>0.929160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IPV</td>\n",
       "      <td>-0.403987</td>\n",
       "      <td>0.403987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NOTA_POR_MISSING</td>\n",
       "      <td>0.370303</td>\n",
       "      <td>0.370303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NOTA_MAT_MISSING</td>\n",
       "      <td>0.370303</td>\n",
       "      <td>0.370303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FASE</td>\n",
       "      <td>0.297828</td>\n",
       "      <td>0.297828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDADE</td>\n",
       "      <td>-0.217200</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IAN</td>\n",
       "      <td>0.210977</td>\n",
       "      <td>0.210977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IPS</td>\n",
       "      <td>0.204813</td>\n",
       "      <td>0.204813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEFASAGEM</td>\n",
       "      <td>-0.167195</td>\n",
       "      <td>0.167195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IDA</td>\n",
       "      <td>-0.131117</td>\n",
       "      <td>0.131117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NOTA_MAT</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.052785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IAA</td>\n",
       "      <td>0.047133</td>\n",
       "      <td>0.047133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NOTA_POR</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.020145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IEG_MISSING</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature      coef  abs_coef\n",
       "5                IEG -0.929160  0.929160\n",
       "9                IPV -0.403987  0.403987\n",
       "17  NOTA_POR_MISSING  0.370303  0.370303\n",
       "16  NOTA_MAT_MISSING  0.370303  0.370303\n",
       "2               FASE  0.297828  0.297828\n",
       "1              IDADE -0.217200  0.217200\n",
       "7                IAN  0.210977  0.210977\n",
       "8                IPS  0.204813  0.204813\n",
       "3          DEFASAGEM -0.167195  0.167195\n",
       "6                IDA -0.131117  0.131117\n",
       "10          NOTA_MAT  0.052785  0.052785\n",
       "4                IAA  0.047133  0.047133\n",
       "11          NOTA_POR  0.020145  0.020145\n",
       "0                ANO  0.000000  0.000000\n",
       "13       IEG_MISSING  0.000000  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# recupera o modelo treinado\n",
    "lr = pipe.named_steps[\"lr\"]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"coef\": lr.coef_[0]\n",
    "})\n",
    "\n",
    "# ordena por impacto absoluto\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df = coef_df.sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "coef_df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
